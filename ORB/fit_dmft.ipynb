{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Initialization----------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import tensorflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import softmax\n",
    "from scipy import sparse\n",
    "from scipy.optimize import leastsq\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n",
    "pi=math.pi\n",
    "exp=math.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for multi-output regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_up=np.loadtxt('Gfupin.dat') # input with 2,4,6 orbital 100 random U\n",
    "inp_dw=np.loadtxt('Gfdwin.dat')\n",
    "out_up=np.loadtxt('Gfupout.dat') # output with 8 orbital 100\n",
    "out_dw=np.loadtxt('Gfdwout.dat')\n",
    "#------------------To cross check we reshape-------------\n",
    "Ginp_up=np.reshape(inp_up, (500,256*3), order='C')\n",
    "Ginp_dw=np.reshape(inp_dw, (500,256*3),order='C')\n",
    "Gout_up=np.reshape(out_up, (500,256),order='C')\n",
    "Gout_dw=np.reshape(out_dw, (500,256),order='C')\n",
    "\n",
    "tmp=np.reshape(Ginp_up,(500,256,3))\n",
    "tmpdw=np.reshape(Ginp_dw,(500,256,3))\n",
    "\n",
    "interaction=np.loadtxt('../U.dat')\n",
    "dfint=pd.DataFrame(data=interaction)\n",
    "dfint.hist(bins=100, grid=False, figsize=(4,4), color='#86bf91', zorder=2, rwidth=0.9)\n",
    "plt.xlabel('U')\n",
    "plt.ylabel(\"units\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tmp[66,:,1])\n",
    "plt.xlabel(r'$\\tau$')\n",
    "plt.ylabel(r'$G(\\tau)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn=np.arange(0,256)\n",
    "x=wn\n",
    "y=tmp[66,:,1]+0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion fit using least square\n",
    "def func2(params, x, y):\n",
    "    a,b,c,d,e=params[0], params[1], params[2],params[3], params[4]\n",
    "    residual=y-(a*np.exp(b*x**2-c*x-d)+e)\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0, 0, 0, 0, 0]\n",
    "result = leastsq(func2, params, (x, y),maxfev=20000)\n",
    "a, b, c,d, e=result[0][0], result[0][1], result[0][2],result[0][3], result[0][4]\n",
    "print(a,b,c,d,e)\n",
    "yfit1=a*np.exp(b*x**2-c*x-d)+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=wn\n",
    "plt.plot(x, y, 'bo', label=\"y-original\")\n",
    "plt.plot(x, yfit1, color=\"red\", label=\"y=a*exp(b*x^2-c*x-d)+e\")\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc='best', fancybox=True, shadow=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_f=[]\n",
    "for i in range(500): \n",
    "    params = [0, 0, 0, 0, 0]\n",
    "    ydata=tmp[i,:,0]+0.0001\n",
    "    result = leastsq(func2, params, (wn, ydata),maxfev=20000)\n",
    "    a, b, c, d, e=result[0][0], result[0][1], result[0][2],result[0][3], result[0][4]\n",
    "    print(i)\n",
    "    popt_f.append([a,b,c,d,e])\n",
    "\n",
    "d2orb=pd.DataFrame(popt_f)   \n",
    "d2orb.columns=['param02','param12','param22','param32','param42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-alloy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(d2orb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2orb\n",
    "#print(d2orb.describe())\n",
    "d2orb.hist(column=[\"param02\", \"param12\", \"param22\", \"param32\", \"param42\"], sharey=True, figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "trans = MaxAbsScaler()\n",
    "data = trans.fit_transform(d2orb)\n",
    "data2=pd.DataFrame(data)\n",
    "data2.columns=['scaled_param02','scaled_param12','scaled_param22','scaled_param32','scaled_param42']\n",
    "data2.hist(column=['scaled_param02','scaled_param12','scaled_param22','scaled_param32','scaled_param42'],sharey=True, figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_f=[]\n",
    "for i in range(500):\n",
    "    params = [0, 0, 0, 0, 0]\n",
    "    ydata=tmp[i,:,1]+0.001\n",
    "    result = leastsq(func2, params, (wn, ydata), maxfev=20000)\n",
    "    a, b, c,d, e=result[0][0], result[0][1], result[0][2],result[0][3], result[0][4]\n",
    "    print(i)\n",
    "    popt_f.append([a,b,c,d,e])\n",
    "d4orb=pd.DataFrame(popt_f)\n",
    "d4orb.columns=['param04','param14','param24','param34','param44']\n",
    "d4orb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4orb\n",
    "#print(d4orb.describe())\n",
    "d4orb.hist(column=[\"param04\", \"param14\", \"param24\", \"param34\", \"param44\"], sharey=True, figsize=(8,8))\n",
    "plt.show()\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "trans = MaxAbsScaler()\n",
    "data = trans.fit_transform(d4orb)\n",
    "data4=pd.DataFrame(data)\n",
    "data4.columns=['scaled_param04','scaled_param14','scaled_param24','scaled_param34','scaled_param44']\n",
    "data4.hist(column=['scaled_param04','scaled_param14','scaled_param24','scaled_param34','scaled_param44'],sharey=True, figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_f=[]\n",
    "for i in range(500):\n",
    "    params = [0, 0, 0, 0, 0]\n",
    "    ydata=tmp[i,:,2]+0.0001\n",
    "    result = leastsq(func2, params, (wn, ydata),maxfev=20000)\n",
    "    a, b, c,d, e=result[0][0], result[0][1], result[0][2],result[0][3], result[0][4]\n",
    "    print(i)\n",
    "    popt_f.append([a,b,c,d,e])\n",
    "d6orb=pd.DataFrame(popt_f)\n",
    "d6orb.columns=['param06','param16','param26','param36','param46']\n",
    "d6orb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "d6orb\n",
    "#print(d6orb.describe())\n",
    "d6orb.hist(column=[\"param06\", \"param16\", \"param26\", \"param36\", \"param46\"], sharey=True, figsize=(8,8))\n",
    "plt.show()\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "trans = MaxAbsScaler()\n",
    "data = trans.fit_transform(d6orb)\n",
    "data6=pd.DataFrame(data)\n",
    "data6.columns=['scaled_param06','scaled_param16','scaled_param26','scaled_param36','scaled_param46']\n",
    "data6.hist(column=['scaled_param06','scaled_param16','scaled_param26','scaled_param36','scaled_param46'],sharey=True, figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_f=[]\n",
    "for i in range(500):\n",
    "    params = [0, 0, 0, 0, 0]\n",
    "    ydata=Gout_up[i,:]+0.0001\n",
    "    result = leastsq(func2, params, (wn, ydata),maxfev=20000)\n",
    "    a, b, c,d, e=result[0][0], result[0][1], result[0][2],result[0][3], result[0][4]\n",
    "    print(i)\n",
    "    popt_f.append([a,b,c,d,e])\n",
    "d8orb=pd.DataFrame(popt_f)\n",
    "d8orb.columns=['param08','param18','param28','param38','param48']\n",
    "d8orb.hist(column='param08',bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "d8orb\n",
    "#print(d8orb.describe())\n",
    "d8orb.hist(column=[\"param08\", \"param18\", \"param28\", \"param38\", \"param48\"], sharey=True, figsize=(8,8))\n",
    "plt.show()\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "trans = MaxAbsScaler()\n",
    "data = trans.fit_transform(d8orb)\n",
    "data8=pd.DataFrame(data)\n",
    "data8.columns=['scaled_param08','scaled_param18','scaled_param28','scaled_param38','scaled_param48']\n",
    "data8.hist(column=['scaled_param08','scaled_param18','scaled_param28','scaled_param38','scaled_param48'],sharey=True, figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gin = pd.concat([data2, data4,data6], axis=1)\n",
    "Gin_t=pd.concat([d2orb, d4orb,d6orb], axis=1)\n",
    "X=Gin.to_numpy()\n",
    "X_t=Gin_t.to_numpy()\n",
    "y=data8.to_numpy()\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)\n",
    "X_train=X[0:400,:]\n",
    "X_test=X[400:500,:]\n",
    "X_test_t=X_t[400:500,:]\n",
    "y_train=y[0:400,:]\n",
    "y_test=y[400:500,:]\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=15, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=10, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Gin, data8, test_size=0.1, random_state=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GaussianNoise\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "values = [1e-4]\n",
    "all_train, all_test = list(), list()\n",
    "for params in values:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu',input_shape=(15,)))\n",
    "    model.add(Dense(5, activation = 'relu'))\n",
    "    model.add(Dense(5))\n",
    "    #model.compile(loss = 'mse', optimizer = RMSprop(), metrics = ['accuracy'])\n",
    "    model.compile(loss = 'mae', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    history = model.fit(X_train, y_train, batch_size=20, epochs = 2000, verbose = 1, validation_data=(X_test,y_test))\n",
    "    _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Param: %f, Train: %.3f, Test: %.3f' % (params, train_acc, test_acc))\n",
    "    all_train.append(train_acc)\n",
    "    all_test.append(test_acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylim(0.0,0.65)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-church",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='valLoss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test) \n",
    "print(prediction.shape) \n",
    "ypred=prediction\n",
    "print(ypred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred\n",
    "ypred_h=pd.DataFrame(ypred)\n",
    "ypred_h.hist()\n",
    "data8.iloc[400:500,:].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ypred[0][0]\n",
    "b=ypred[0][1]\n",
    "c=ypred[0][2]\n",
    "d=ypred[0][3]\n",
    "e=ypred[0][4]\n",
    "print(a,b,c,d,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit1=a*np.exp(b*x**2-c*x-d)+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, yfit1, color=\"red\", label=\"y=ax^2+bx+c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-dryer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
